{"cells":[{"cell_type":"markdown","source":["![polina](https://raw.githubusercontent.com/PolinaRus/CIS_8795/master/polina.png)\n\n#What is Machine Learning?\nMachine learning is a set of techniques, which help in dealing with vast data in the most intelligent fashion (by developing algorithms or set of logical rules) to derive actionable insights (delivering search for users in this case)."],"metadata":{}},{"cell_type":"markdown","source":["#What are the steps used in Machine Learning?\n\nThere are 5 basic steps used to perform a machine learning task:\n\n* **Collecting data:** Be it the raw data from excel, access, text files etc., this step (gathering past data) forms the foundation of the future learning. The better the variety, density and volume of relevant data, better the learning prospects for the machine becomes.\n* **Preparing the data:** Any analytical process thrives on the quality of the data used. One needs to spend time determining the quality of data and then taking steps for fixing issues such as missing data and treatment of outliers. Exploratory analysis is perhaps one method to study the nuances of the data in details thereby burgeoning the nutritional content of the data.\n* **Training a model:** This step involves choosing the appropriate algorithm and representation of data in the form of the model. The cleaned data is split into two parts – train and test (proportion depending on the prerequisites); the first part (training data) is used for developing the model. The second part (test data), is used as a reference.\n* **Evaluating the model:** To test the accuracy, the second part of the data (holdout / test data) is used. This step determines the precision in the choice of the algorithm based on the outcome. A better test to check accuracy of model is to see its performance on data which was not used at all during model build.\n* **Improving the performance:** This step might involve choosing a different model altogether or introducing more variables to augment the efficiency. That’s why significant amount of time needs to be spent in data collection and preparation"],"metadata":{}},{"cell_type":"markdown","source":["#What are the types of Machine Learning algorithms?\n\n####Supervised Learning / Predictive models:\nPredictive model as the name suggests is used to predict the future outcome based on the historical data. Predictive models are normally given clear instructions right from the beginning as in what needs to be learnt and how it needs to be learnt. These class of learning algorithms are termed as Supervised Learning.\n\nFor example: Supervised Learning is used when a marketing company is trying to find out which customers are likely to churn. We can also use it to predict the likelihood of occurrence of perils like earthquakes, tornadoes etc. with an aim to determine the Total Insurance Value. Some examples of algorithms used are: Nearest neighbour, Naïve Bayes, Decision Trees, Regression etc.\n\n\n####Unsupervised learning / Descriptive models:\nIt is used to train descriptive models where no target is set and no single feature is important than the other. The case of unsupervised learning can be: When a retailer wishes to find out what are the combination of products, customers tends to buy more frequently. Furthermore, in pharmaceutical industry, unsupervised learning may be used to predict which diseases are likely to occur along with diabetes. Example of algorithm used here is: K- means Clustering Algorithm"],"metadata":{}},{"cell_type":"markdown","source":["#Regression\nRegression analysis is a statistical tool for the investigation of relationships between variables. Usually, the investigator seeks to examine the causal effect of one variable upon another. It attempts to determine the strength of the relationship between one dependent variable and a series of other changing variables known as independent variables. The two basic types of regression are linear regression and multiple regression. Linear regression uses one independent variable to explain and/or predict the dependent variable, while multiple regression uses two or more independent variables to predict the outcome. \n\nThe general form of each type of regression is: \n\n* **Linear Regression:** Y = a + bX + u\n* **Multiple Regression:** Y = a + b1X1 + b2X2 + b3X3 + ... + btXt + u\n\nWhere:\n* Y= the variable that we are trying to predict\n* X= the variable that we are using to predict Y\n* a= the intercept\n* b= the slope\n* u= the regression residual"],"metadata":{}},{"cell_type":"markdown","source":["## Load Data Using curl\n* **Line 1:** Use **%sh** - This allows you to execute shell code in notebook\n* **Line 2:** Make a new directory called **cis** on the machine\n* **Line 3:** Use **curl** to download a file and locate it in the **cis** directory by assigning a name and format *(in the example below, the format is changed to **CSV**)*\n* **Line 4:** Check if the file is downloaded and listed in the directory"],"metadata":{}},{"cell_type":"code","source":["%sh \nmkdir -p life_pred\ncurl 'https://raw.githubusercontent.com/PolinaRus/CIS_8795/master/Life_Expectancy.csv' > life_pred/life_expectancy.csv\nls /databricks/driver/life_pred"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### Check File Directory\n* Use **%fs** to check file path, name, and size"],"metadata":{}},{"cell_type":"code","source":["%fs \nls file:/databricks/driver/life_pred"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Create Dataframe\n* **Line 1:** Set File Path\n* **Line 2:** Create a Dataframe **data**\n* **Line 3:** Count rows in the Dataframe **data**\n* Line 3: Show the Newly Created Dataframe **data**"],"metadata":{}},{"cell_type":"code","source":["data = spark.read.format(\"com.databricks.spark.csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"file:/databricks/driver/life_pred/life_expectancy.csv\")\ndata.cache()  # Cache data for faster reuse\ndata.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Display Newly Created Dataframe **data**"],"metadata":{}},{"cell_type":"code","source":["display(data)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Print the schema of the dataframe **data**"],"metadata":{}},{"cell_type":"code","source":["data.printSchema()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Drop rows with missing values and count the rows again"],"metadata":{}},{"cell_type":"code","source":["data = data.dropna() \ndata.count()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Create table that lets us access the table from our SQL notebook!"],"metadata":{}},{"cell_type":"code","source":["data.createOrReplaceTempView(\"life_exp\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["Display the newly created table **life_exp**"],"metadata":{}},{"cell_type":"code","source":["%sql select * from life_exp"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["%sql\nselect Population, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["%sql\nselect Labor_Force as Labor_Force, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["%sql\nselect GDP, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["%sql\nselect Urbanization, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["%sql\nselect Literacy, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["%sql\nselect Below_Poverty_Line, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["%sql\nselect Median_Age, Life_Expectancy from life_exp"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Create DataFrame with just the data we want to run linear regression\ndf = spark.sql(\"select GDP, Life_Expectancy as label from life_exp\")\ndisplay(df)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(\n    inputCols=[\"GDP\"],\n    outputCol=\"features\")\noutput = assembler.transform(df)\ndisplay(output.select(\"features\", \"label\"))"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# Import LinearRegression class\nfrom pyspark.ml.regression import LinearRegression\n\n# Define LinearRegression algorithm\nlr = LinearRegression()\n\n# Fit 2 models, using different regularization parameters\nmodelA = lr.fit(output, {lr.regParam:0.0})\nmodelB = lr.fit(output, {lr.regParam:100.0})"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["print \">>>> ModelA intercept: %r, coefficient: %r\" % (modelA.intercept, modelA.coefficients[0])"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["print \">>>> ModelB intercept: %r, coefficient: %r\" % (modelB.intercept, modelB.coefficients[0])"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# Make predictions\npredictionsA = modelA.transform(output)\ndisplay(predictionsA)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(metricName=\"rmse\")\nRMSE = evaluator.evaluate(predictionsA)\nprint(\"ModelA: Root Mean Squared Error = \" + str(RMSE))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["predictionsB = modelB.transform(output)\nRMSE = evaluator.evaluate(predictionsB)\nprint(\"ModelB: Root Mean Squared Error = \" + str(RMSE))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["import numpy as np\nfrom pandas import *\nfrom ggplot import *\n\nGDP = output.rdd.map(lambda p: (p.features[0])).collect()\nLife_Expectancy = output.rdd.map(lambda p: (p.label)).collect()\npredA = predictionsA.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\npredB = predictionsB.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\n\npydf = DataFrame({'GDP':GDP,'Life_Expectancy':Life_Expectancy,'predA':predA, 'predB':predB})"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["pydf"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["pp = ggplot(pydf, aes('GDP','Life_Expectancy'))  + \\\n    geom_point(color='blue') \ndisplay(pp)\n"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["p = ggplot(pydf, aes('GDP','Life_Expectancy')) + \\\n    geom_point(color='blue') + \\\n    geom_line(pydf, aes('GDP','predA'), color='red') + \\\n    geom_line(pydf, aes('GDP','predB'), color='green') + \\\n    scale_x_log10() + scale_y_log10()\ndisplay(p)"],"metadata":{},"outputs":[],"execution_count":39}],"metadata":{"name":"Linear Regression","notebookId":1412753628042160},"nbformat":4,"nbformat_minor":0}
